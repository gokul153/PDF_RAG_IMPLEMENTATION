# ğŸ“„ Conversational RAG with PDF Upload and Chat History

This project implements a **Conversational Retrieval-Augmented Generation (RAG)** system that allows users to:
- Upload a PDF ğŸ“‘
- Ask context-aware questions ğŸ¤–
- View history-aware responses using **LLMs** from **Groq API**
- Persist chat sessions using **Streamlit state management**

---

## ğŸš€ Features

- âœ… Upload single PDF and extract content
- âœ… Chunking and vectorization using HuggingFace Embeddings + ChromaDB
- âœ… Chat history tracking using LangChain's `RunnableWithMessageHistory`
- âœ… Question reformulation using contextual prompts
- âœ… Real-time responses powered by Groq LLMs (e.g. `Gemma2-9b-It`)
- âœ… Clean Streamlit UI

---

## ğŸ§  Tech Stack

- **LangChain**: Chains, prompts, chat history management
- **Groq LLMs**: Ultra-fast inference using `llama3` or `gemma`
- **HuggingFace Embeddings**: `all-MiniLM-L6-v2` for semantic search
- **ChromaDB**: Local vectorstore
- **Streamlit**: UI interface
- **PDF Parsing**: `PyPDFLoader`

---

## ğŸ› ï¸ Setup

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/conversational-rag-pdf.git
cd conversational-rag-pdf
